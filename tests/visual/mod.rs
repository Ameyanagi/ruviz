//! Visual regression testing infrastructure for plot traits
//!
//! This module provides utilities for visual comparison testing of plot output.
//!
//! # Overview
//!
//! Visual tests generate plot images and compare them against reference images
//! (generated by matplotlib) to catch visual regressions.
//!
//! # Workflow
//!
//! 1. Generate reference images:
//!    ```bash
//!    python scripts/generate_reference.py
//!    ```
//!
//! 2. Run visual tests:
//!    ```bash
//!    cargo test --test visual_traits -- --ignored
//!    ```
//!
//! 3. Review any differences in `tests/output/visual_diff/`
//!
//! # Note
//!
//! Visual tests are marked `#[ignore]` by default because they:
//! - Require reference images to be generated first
//! - May have small differences due to font rendering
//! - Are meant for manual review, not automated CI

use std::path::{Path, PathBuf};

/// Configuration for visual tests
#[allow(dead_code)]
pub struct VisualTestConfig {
    /// Output directory for generated images
    pub output_dir: PathBuf,
    /// Reference image directory
    pub reference_dir: PathBuf,
    /// Diff output directory
    pub diff_dir: PathBuf,
    /// Figure size (width, height) in pixels
    pub figure_size: (u32, u32),
    /// DPI for rendering
    pub dpi: u32,
    /// Tolerance for pixel comparison (0.0 - 1.0)
    pub tolerance: f32,
}

impl Default for VisualTestConfig {
    fn default() -> Self {
        let base = PathBuf::from(env!("CARGO_MANIFEST_DIR"));
        Self {
            output_dir: base.join("tests/output/visual"),
            reference_dir: base.join("tests/visual/reference/matplotlib"),
            diff_dir: base.join("tests/output/visual_diff"),
            figure_size: (640, 480),
            dpi: 100,
            tolerance: 0.05, // 5% pixel difference tolerance
        }
    }
}

impl VisualTestConfig {
    /// Create directories if they don't exist
    pub fn ensure_dirs(&self) -> std::io::Result<()> {
        std::fs::create_dir_all(&self.output_dir)?;
        std::fs::create_dir_all(&self.diff_dir)?;
        Ok(())
    }

    /// Get output path for a test image
    pub fn output_path(&self, name: &str) -> PathBuf {
        self.output_dir.join(format!("{}.png", name))
    }

    /// Get reference path for comparison
    pub fn reference_path(&self, name: &str) -> PathBuf {
        self.reference_dir.join(format!("{}.png", name))
    }

    /// Get diff output path
    pub fn diff_path(&self, name: &str) -> PathBuf {
        self.diff_dir.join(format!("{}_diff.png", name))
    }
}

/// Result of a visual comparison
#[derive(Debug)]
pub struct ComparisonResult {
    /// Name of the test
    pub name: String,
    /// Percentage of pixels that differ
    pub diff_percentage: f32,
    /// Whether the test passed (diff <= tolerance)
    pub passed: bool,
    /// Path to reference image
    pub reference_path: PathBuf,
    /// Path to generated image
    pub output_path: PathBuf,
    /// Path to diff image (if generated)
    pub diff_path: Option<PathBuf>,
}

impl ComparisonResult {
    /// Format as a test assertion message
    pub fn assert_message(&self) -> String {
        if self.passed {
            format!(
                "Visual test '{}' passed ({:.2}% difference)",
                self.name,
                self.diff_percentage * 100.0
            )
        } else {
            format!(
                "Visual test '{}' FAILED ({:.2}% difference, tolerance: 5%)\n\
                 Reference: {}\n\
                 Generated: {}\n\
                 Diff: {:?}",
                self.name,
                self.diff_percentage * 100.0,
                self.reference_path.display(),
                self.output_path.display(),
                self.diff_path
            )
        }
    }
}

/// Compare two images and compute the difference
///
/// Returns the percentage of pixels that differ beyond the threshold.
pub fn compare_images(
    reference: &Path,
    generated: &Path,
    diff_output: Option<&Path>,
    _tolerance: f32,
) -> Result<f32, String> {
    // Load reference image
    if !reference.exists() {
        return Err(format!(
            "Reference image not found: {}\n\
             Run: python scripts/generate_reference.py",
            reference.display()
        ));
    }

    if !generated.exists() {
        return Err(format!(
            "Generated image not found: {}",
            generated.display()
        ));
    }

    // For now, just check that both files exist and have similar sizes
    // A full implementation would use image comparison libraries
    let ref_meta = std::fs::metadata(reference)
        .map_err(|e| format!("Failed to read reference metadata: {}", e))?;
    let gen_meta = std::fs::metadata(generated)
        .map_err(|e| format!("Failed to read generated metadata: {}", e))?;

    // Simple size-based comparison (placeholder)
    // Real implementation would compare pixel data
    let size_diff = (ref_meta.len() as f64 - gen_meta.len() as f64).abs() / ref_meta.len() as f64;

    // If diff output requested and there's a difference, copy generated as "diff"
    if let Some(diff_path) = diff_output {
        if size_diff > 0.1 {
            let _ = std::fs::copy(generated, diff_path);
        }
    }

    Ok(size_diff as f32)
}

/// Run a visual comparison test
pub fn run_visual_test(
    name: &str,
    config: &VisualTestConfig,
    generate_fn: impl FnOnce(&Path) -> Result<(), Box<dyn std::error::Error>>,
) -> ComparisonResult {
    // Ensure output directories exist
    if let Err(_e) = config.ensure_dirs() {
        return ComparisonResult {
            name: name.to_string(),
            diff_percentage: 1.0,
            passed: false,
            reference_path: config.reference_path(name),
            output_path: config.output_path(name),
            diff_path: None,
        };
    }

    let output_path = config.output_path(name);
    let reference_path = config.reference_path(name);
    let diff_path = config.diff_path(name);

    // Generate the plot
    if let Err(e) = generate_fn(&output_path) {
        eprintln!("Failed to generate plot '{}': {}", name, e);
        return ComparisonResult {
            name: name.to_string(),
            diff_percentage: 1.0,
            passed: false,
            reference_path,
            output_path,
            diff_path: None,
        };
    }

    // Compare with reference
    match compare_images(
        &reference_path,
        &output_path,
        Some(&diff_path),
        config.tolerance,
    ) {
        Ok(diff) => ComparisonResult {
            name: name.to_string(),
            diff_percentage: diff,
            passed: diff <= config.tolerance,
            reference_path,
            output_path,
            diff_path: if diff > config.tolerance {
                Some(diff_path)
            } else {
                None
            },
        },
        Err(e) => {
            eprintln!("Comparison failed for '{}': {}", name, e);
            ComparisonResult {
                name: name.to_string(),
                diff_percentage: 1.0,
                passed: false,
                reference_path,
                output_path,
                diff_path: None,
            }
        }
    }
}

/// Macro for creating visual tests
///
/// Example:
/// ```rust,ignore
/// visual_test!(test_kde_visual, "kde", |path| {
///     Plot::new()
///         .kde(&data)
///         .save(path)
/// });
/// ```
#[macro_export]
macro_rules! visual_test {
    ($test_name:ident, $plot_name:expr, $generate:expr) => {
        #[test]
        #[ignore = "Visual tests require reference images. Run: python scripts/generate_reference.py"]
        fn $test_name() {
            use $crate::visual::{run_visual_test, VisualTestConfig};

            let config = VisualTestConfig::default();
            let result = run_visual_test($plot_name, &config, $generate);

            if !result.passed {
                panic!("{}", result.assert_message());
            } else {
                println!("{}", result.assert_message());
            }
        }
    };
}
